{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "Dbc9j-vz2Px-",
    "outputId": "56b4a091-80cc-42ba-a2e9-ce28739443fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "qv-QM2NtKLTy",
    "outputId": "e5225730-4d3b-4fca-d6a4-b61f3c842a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.3.0\n",
      "GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxhsWZPeLZJt"
   },
   "source": [
    "Essential info about tagged entities:\n",
    "\n",
    "    o-geo = Geographical Entity\n",
    "    o-org = Organization\n",
    "    o-per = Person\n",
    "    o-gpe = Geopolitical Entity\n",
    "    o-tim = Time indicator\n",
    "    o-art = Artifact\n",
    "    o-eve = Event\n",
    "    o-nat = Natural Phenomenon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "4mybe1soLgmg",
    "outputId": "b775a8fd-66f8-4f08-ba7f-f78d6b350dbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1   Sentence: 1             of   IN      O\n",
       "2   Sentence: 1  demonstrators  NNS      O\n",
       "3   Sentence: 1           have  VBP      O\n",
       "4   Sentence: 1        marched  VBN      O\n",
       "5   Sentence: 1        through   IN      O\n",
       "6   Sentence: 1         London  NNP  B-geo\n",
       "7   Sentence: 1             to   TO      O\n",
       "8   Sentence: 1        protest   VB      O\n",
       "9   Sentence: 1            the   DT      O\n",
       "10  Sentence: 1            war   NN      O\n",
       "11  Sentence: 1             in   IN      O\n",
       "12  Sentence: 1           Iraq  NNP  B-geo\n",
       "13  Sentence: 1            and   CC      O\n",
       "14  Sentence: 1         demand   VB      O\n",
       "15  Sentence: 1            the   DT      O\n",
       "16  Sentence: 1     withdrawal   NN      O\n",
       "17  Sentence: 1             of   IN      O\n",
       "18  Sentence: 1        British   JJ  B-gpe\n",
       "19  Sentence: 1         troops  NNS      O"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('/content/drive/My Drive/Colab Notebooks/data_sets_for_training/ner_dataset.csv',encoding='latin1')\n",
    "data=data.fillna(method='ffill')\n",
    "data.head(20)\n",
    "\n",
    "\n",
    "# The first 20 is one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "l0YmkA1dOJBs",
    "outputId": "f64b8108-9449-4464-bb5d-637dc072b29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in corpus: 35178\n",
      "Unique tags in corpus: 17\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
    "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a1MZjMQ8N-wG",
    "outputId": "21e478c5-46cb-472d-a462-6658423a67b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "num_words = len(words)\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fwi3v6yfOCvq",
    "outputId": "cc146637-98fb-46cf-8904-7dfc3a5d3052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "num_tags = len(tags)\n",
    "num_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UY2whiV0Pp1y"
   },
   "source": [
    "we have 47958 sentences in our dataset, 35179 different words and 17 different named entities (Tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1lKJCt7QOsr"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tNk5LKgSWH8"
   },
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "T4OhTuNiOg2M",
    "outputId": "e6ce5e9c-ca50-49e9-8bc4-cf1ba6542e37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoqtPREzS648"
   },
   "outputs": [],
   "source": [
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_icglhjiUD2J",
    "outputId": "16b45810-f1e3-41ec-a9b5-857c0c3caf2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Specialist': 1,\n",
       " 'marathoner': 2,\n",
       " 'multi-billion-dollar': 3,\n",
       " 'carriages': 4,\n",
       " 'registry': 5,\n",
       " 'knife-wielding': 6,\n",
       " 'Oo': 7,\n",
       " 'Complaints': 8,\n",
       " 'crossfire': 9,\n",
       " \"al-U'Zayra\": 10,\n",
       " 'Revolution': 11,\n",
       " 'Puebla': 12,\n",
       " 'dissipate': 13,\n",
       " 'identifying': 14,\n",
       " 'Asset': 15,\n",
       " 'Fijians': 16,\n",
       " 'Rabin': 17,\n",
       " 'declining': 18,\n",
       " 'Tendulkar': 19,\n",
       " 'Competition': 20,\n",
       " 'convening': 21,\n",
       " 'Hour': 22,\n",
       " 'Diaz': 23,\n",
       " 'dissipating': 24,\n",
       " 'harmed': 25,\n",
       " 'Ereli': 26,\n",
       " 'Karo': 27,\n",
       " 'Seismologists': 28,\n",
       " 'springboard': 29,\n",
       " '80s': 30,\n",
       " '62': 31,\n",
       " 'Every': 32,\n",
       " 'English-speaking': 33,\n",
       " 'Barre': 34,\n",
       " 'Opel': 35,\n",
       " '230': 36,\n",
       " 'catheter': 37,\n",
       " 'Klebnikov': 38,\n",
       " 'Bells': 39,\n",
       " 'survey': 40,\n",
       " 'findings': 41,\n",
       " 'brook': 42,\n",
       " 'deadline': 43,\n",
       " 'announcement': 44,\n",
       " 'internal': 45,\n",
       " 'credited': 46,\n",
       " 'Mashonaland': 47,\n",
       " 'Tian': 48,\n",
       " 'recommendation': 49,\n",
       " 'Drinan': 50,\n",
       " 'Exiles': 51,\n",
       " 'Harriet': 52,\n",
       " 'Cabeza': 53,\n",
       " 'consensus': 54,\n",
       " 'Concentration': 55,\n",
       " 'curtains': 56,\n",
       " 'Performing': 57,\n",
       " 'Sergey': 58,\n",
       " 'Graz': 59,\n",
       " 'Bavaria': 60,\n",
       " 'Jim': 61,\n",
       " 'Hoffman': 62,\n",
       " 'commercially-available': 63,\n",
       " '54-page': 64,\n",
       " 'insulting': 65,\n",
       " 'dignitary': 66,\n",
       " 'leaks': 67,\n",
       " 'taking': 68,\n",
       " 'Hafez': 69,\n",
       " 'Telecom': 70,\n",
       " 'Omollo': 71,\n",
       " 'disrupts': 72,\n",
       " '62-year-old': 73,\n",
       " 'maimed': 74,\n",
       " 'concocted': 75,\n",
       " 'Incumbent': 76,\n",
       " 'Eskisehir': 77,\n",
       " 'Stones': 78,\n",
       " 'Knicks': 79,\n",
       " '95': 80,\n",
       " 'controlling': 81,\n",
       " 'Mahamane': 82,\n",
       " 'siphon': 83,\n",
       " 'Anti-Kidnapping': 84,\n",
       " 'sub-continent': 85,\n",
       " 'AT&T': 86,\n",
       " 'Anti-Bush': 87,\n",
       " '1.2': 88,\n",
       " 'asylum-seeker': 89,\n",
       " 'Viewers': 90,\n",
       " 'Berlusconi': 91,\n",
       " 'pall': 92,\n",
       " 'biased': 93,\n",
       " 'large-caliber': 94,\n",
       " 'mere': 95,\n",
       " 'soothing': 96,\n",
       " 'costumes': 97,\n",
       " 'Blizzard-like': 98,\n",
       " '18-year': 99,\n",
       " 'A.W.B.': 100,\n",
       " 'co-founder': 101,\n",
       " 'Macchiavello': 102,\n",
       " 'least': 103,\n",
       " 'Abe': 104,\n",
       " 'Romania': 105,\n",
       " 'anti-Japan': 106,\n",
       " 'defender': 107,\n",
       " 'typhoon-triggered': 108,\n",
       " 'dollar-denominated': 109,\n",
       " 'dripped': 110,\n",
       " 'stringent': 111,\n",
       " 'Itai': 112,\n",
       " 'fled': 113,\n",
       " 'Turkish-Armenian': 114,\n",
       " 'selections': 115,\n",
       " 'Durham': 116,\n",
       " 'smell': 117,\n",
       " 'Venezuelan': 118,\n",
       " 'Bond': 119,\n",
       " 'Kira': 120,\n",
       " 'Falluja': 121,\n",
       " 'rotate': 122,\n",
       " 'BARE': 123,\n",
       " 'baby': 124,\n",
       " 'nationalizing': 125,\n",
       " 'Rezayee': 126,\n",
       " 'sermons': 127,\n",
       " 'Uruzgan': 128,\n",
       " 'contagious': 129,\n",
       " 'signifies': 130,\n",
       " 'desalinization': 131,\n",
       " '203': 132,\n",
       " 'Maltese': 133,\n",
       " 'empires': 134,\n",
       " 'democracy-building': 135,\n",
       " 'combat-related': 136,\n",
       " 'Outdoors': 137,\n",
       " 'abrasive': 138,\n",
       " 'Kalamazoo': 139,\n",
       " 'Jayprakash': 140,\n",
       " 'stems': 141,\n",
       " 'rush': 142,\n",
       " '35-member': 143,\n",
       " 'Our': 144,\n",
       " 'abducting': 145,\n",
       " 'Adolphus': 146,\n",
       " 'Jalalzadeh': 147,\n",
       " 'Solis': 148,\n",
       " 'emphasis': 149,\n",
       " '90,000': 150,\n",
       " 'rained': 151,\n",
       " 'Isfahan': 152,\n",
       " 'subsidy': 153,\n",
       " 'barrier': 154,\n",
       " 'Douste-Blazy': 155,\n",
       " 'Commission': 156,\n",
       " 'Nowak': 157,\n",
       " 'grass-court': 158,\n",
       " 'await': 159,\n",
       " 'floods': 160,\n",
       " 'Ukrainians': 161,\n",
       " 'anytime': 162,\n",
       " 'Khmers': 163,\n",
       " 'gobe': 164,\n",
       " 'Nad-e-Ali': 165,\n",
       " 'transforming': 166,\n",
       " 'Verde': 167,\n",
       " 'Yemen': 168,\n",
       " 'rested': 169,\n",
       " 'dusk': 170,\n",
       " 'rationing': 171,\n",
       " 'Remembrance': 172,\n",
       " 'Cauldron': 173,\n",
       " 'Giving': 174,\n",
       " 'shoving': 175,\n",
       " 'Milli': 176,\n",
       " 'cessation': 177,\n",
       " 'debt-to-GDP': 178,\n",
       " 'Afable': 179,\n",
       " 'facets': 180,\n",
       " 'Bartlett': 181,\n",
       " 'Resident': 182,\n",
       " 'voluntarily': 183,\n",
       " 'heighten': 184,\n",
       " 'victimize': 185,\n",
       " 'enriched': 186,\n",
       " 'correspond': 187,\n",
       " 'Onitsha': 188,\n",
       " 'Aisha': 189,\n",
       " 'divulge': 190,\n",
       " 'G20': 191,\n",
       " 'encounter': 192,\n",
       " 'peacekeeping': 193,\n",
       " 'bipartisan': 194,\n",
       " 'variety': 195,\n",
       " 'edge': 196,\n",
       " '66.15': 197,\n",
       " 'venture': 198,\n",
       " 'Not': 199,\n",
       " 'Bull': 200,\n",
       " 'General-Secretary': 201,\n",
       " 'office': 202,\n",
       " 'Dominicans': 203,\n",
       " 'motel': 204,\n",
       " 'Arauca': 205,\n",
       " 'Cooperation': 206,\n",
       " 'Lisa': 207,\n",
       " 'Sunnis': 208,\n",
       " 'showering': 209,\n",
       " 'Caroni': 210,\n",
       " 'Geneva-based': 211,\n",
       " 'Uninsured': 212,\n",
       " 'Tyrone': 213,\n",
       " 'Wannian': 214,\n",
       " 'premature': 215,\n",
       " 'Flores': 216,\n",
       " 'pride': 217,\n",
       " '122.8': 218,\n",
       " 'industrialize': 219,\n",
       " 'robots': 220,\n",
       " 'widening': 221,\n",
       " 'Teikovo': 222,\n",
       " 'campaigns': 223,\n",
       " 'Buro': 224,\n",
       " 'Space': 225,\n",
       " 'all-inclusive': 226,\n",
       " 'pump': 227,\n",
       " 'eggplant': 228,\n",
       " 'textiles': 229,\n",
       " 'Nuri': 230,\n",
       " 'limited': 231,\n",
       " 'Fleet': 232,\n",
       " 'Hudson-Dean': 233,\n",
       " 'chat': 234,\n",
       " 'winning': 235,\n",
       " 'fared': 236,\n",
       " 'Word': 237,\n",
       " 'symbols': 238,\n",
       " 'affordable': 239,\n",
       " 'extinct': 240,\n",
       " 'Brian': 241,\n",
       " 'Karpinski': 242,\n",
       " 'longer': 243,\n",
       " 'Hoop': 244,\n",
       " 'Mullah': 245,\n",
       " 'vegetable': 246,\n",
       " 'Hezbollah': 247,\n",
       " '728': 248,\n",
       " 'Akhbar': 249,\n",
       " 'Madhuri': 250,\n",
       " 'Al-Arabiya': 251,\n",
       " 'Jay': 252,\n",
       " 'Natama': 253,\n",
       " 'Surrounded': 254,\n",
       " 'doused': 255,\n",
       " 'Hamdania': 256,\n",
       " 'mid-afternoon': 257,\n",
       " 'supporting-actress': 258,\n",
       " 'sooner': 259,\n",
       " '290': 260,\n",
       " 'Francesca': 261,\n",
       " 'wag': 262,\n",
       " '77.95': 263,\n",
       " 'riverine': 264,\n",
       " 'vault': 265,\n",
       " 'loyalty': 266,\n",
       " 'Subsistence': 267,\n",
       " 'WTO': 268,\n",
       " 'Mile': 269,\n",
       " 'Conakry': 270,\n",
       " 'Syarhei': 271,\n",
       " 'Dissatisfied': 272,\n",
       " 'Mahmud': 273,\n",
       " 'Diwan': 274,\n",
       " 'YAYI': 275,\n",
       " 'al-Zawahiri': 276,\n",
       " 'Fat': 277,\n",
       " 'reserve': 278,\n",
       " 'reckon': 279,\n",
       " 'al-Zarqawi': 280,\n",
       " '74,000': 281,\n",
       " 'Nestle': 282,\n",
       " 'Elvis': 283,\n",
       " 'JUDGE': 284,\n",
       " 'agent': 285,\n",
       " 'Telerate': 286,\n",
       " 'Reformists': 287,\n",
       " 'Afghan-international': 288,\n",
       " 'protestors': 289,\n",
       " '21st': 290,\n",
       " '6,78,000': 291,\n",
       " 'ballad': 292,\n",
       " 'Baladiyat': 293,\n",
       " 'nozzles': 294,\n",
       " 'commission': 295,\n",
       " 'Zamfara': 296,\n",
       " 'Peugeot': 297,\n",
       " 'Part': 298,\n",
       " 'Nepalese': 299,\n",
       " 'Old': 300,\n",
       " 'fire': 301,\n",
       " '300-million-dollar': 302,\n",
       " 'uniform': 303,\n",
       " 'six-tenths': 304,\n",
       " 'solved': 305,\n",
       " '82-year-old': 306,\n",
       " 'fracturing': 307,\n",
       " 'pre-emptive': 308,\n",
       " 'Set': 309,\n",
       " 'Ronnie': 310,\n",
       " 'nandrolone': 311,\n",
       " 'Ferrari': 312,\n",
       " 'Saint-Domingue': 313,\n",
       " 'MacLellan': 314,\n",
       " 'Prizes': 315,\n",
       " 'signaling': 316,\n",
       " 'hazards': 317,\n",
       " 'Mowaffaq': 318,\n",
       " 'Annan': 319,\n",
       " 'dining': 320,\n",
       " 're-establish': 321,\n",
       " '352': 322,\n",
       " 'shining': 323,\n",
       " 'uncomplicated': 324,\n",
       " 'Flowers': 325,\n",
       " 'sinking': 326,\n",
       " 'arson': 327,\n",
       " '0': 328,\n",
       " 'posts': 329,\n",
       " '6,00,000': 330,\n",
       " 'Ghalawiya': 331,\n",
       " 'Winfield': 332,\n",
       " 'either': 333,\n",
       " 'Jabr': 334,\n",
       " 'interethnic': 335,\n",
       " 'MILLS': 336,\n",
       " '74th': 337,\n",
       " 'compressed': 338,\n",
       " 'Unicom': 339,\n",
       " 'Ordaz': 340,\n",
       " 'withdrew': 341,\n",
       " 'retirees': 342,\n",
       " 'al-Youm': 343,\n",
       " 'Mekdad': 344,\n",
       " '5-0': 345,\n",
       " 'Lucie': 346,\n",
       " 'Wipha': 347,\n",
       " 'Pakistani': 348,\n",
       " 'Sanha': 349,\n",
       " 'disagree': 350,\n",
       " '413': 351,\n",
       " 'non-peaceful': 352,\n",
       " 'Facing': 353,\n",
       " 'birds': 354,\n",
       " '400-kilometer': 355,\n",
       " 'Make': 356,\n",
       " 'capacity': 357,\n",
       " 'Djibouti': 358,\n",
       " 'Nasiriyah': 359,\n",
       " 'surveyed': 360,\n",
       " 'counterterrorist': 361,\n",
       " 'enjoys': 362,\n",
       " 'grocery': 363,\n",
       " 'Floruan': 364,\n",
       " 'Elfriede': 365,\n",
       " 'Rivers': 366,\n",
       " 'refuel': 367,\n",
       " 'Grand': 368,\n",
       " 'oats': 369,\n",
       " 'once-a-day': 370,\n",
       " 'equipping': 371,\n",
       " 'declined': 372,\n",
       " 'Drawing': 373,\n",
       " 'al-Haidari': 374,\n",
       " 'regulation': 375,\n",
       " 'Physically': 376,\n",
       " 'Yunesi': 377,\n",
       " 'Strains': 378,\n",
       " 'Top-seeded': 379,\n",
       " 'bowling': 380,\n",
       " 'enrolled': 381,\n",
       " 'overall': 382,\n",
       " 'Thai-Burmese': 383,\n",
       " 'Fuzhou': 384,\n",
       " 'Standard': 385,\n",
       " 'build-up': 386,\n",
       " 'Marrero': 387,\n",
       " 'Trincomalee': 388,\n",
       " 'commanded': 389,\n",
       " 'Azur': 390,\n",
       " 'Lerner': 391,\n",
       " 'VimpelCom': 392,\n",
       " 'parties': 393,\n",
       " 'Claimed': 394,\n",
       " 'asset': 395,\n",
       " 'review': 396,\n",
       " 'grips': 397,\n",
       " 'Sinuiju': 398,\n",
       " 'aka': 399,\n",
       " '12.09': 400,\n",
       " 'loans': 401,\n",
       " 'projecting': 402,\n",
       " 'Guillermo': 403,\n",
       " 'protectionism': 404,\n",
       " 'Thein': 405,\n",
       " 'bans': 406,\n",
       " 'Megumi': 407,\n",
       " 'University': 408,\n",
       " 'Entire': 409,\n",
       " 'Preston': 410,\n",
       " '07-Aug': 411,\n",
       " 'detaining': 412,\n",
       " 'requirements': 413,\n",
       " 'WIN': 414,\n",
       " 'extortion': 415,\n",
       " 'documentaries': 416,\n",
       " 'Citicorp': 417,\n",
       " 'aid-distribution': 418,\n",
       " 'located': 419,\n",
       " 'Marja': 420,\n",
       " 'sit-in': 421,\n",
       " 'peregrine': 422,\n",
       " 'tracked': 423,\n",
       " 'TRNC': 424,\n",
       " 'brain': 425,\n",
       " 'demographer': 426,\n",
       " '1888': 427,\n",
       " 'backward': 428,\n",
       " 'Csatia': 429,\n",
       " 'Coleman': 430,\n",
       " 'filled': 431,\n",
       " 'Somali': 432,\n",
       " 'Espinoso': 433,\n",
       " 'intimidation': 434,\n",
       " 'watched': 435,\n",
       " 'closure': 436,\n",
       " 'snow-crusted': 437,\n",
       " 'pens': 438,\n",
       " 'defeating': 439,\n",
       " 'fashioning': 440,\n",
       " 'inductee': 441,\n",
       " 'enjoyed': 442,\n",
       " 'Accords': 443,\n",
       " '1959': 444,\n",
       " '8,700': 445,\n",
       " 'cabinet': 446,\n",
       " '5-member': 447,\n",
       " 'pro-Kurdish': 448,\n",
       " 'faulty': 449,\n",
       " 'Bengali-speaking': 450,\n",
       " 'journeying': 451,\n",
       " 'Bailey': 452,\n",
       " 'quake-stricken': 453,\n",
       " 'Guocong': 454,\n",
       " 'speeches': 455,\n",
       " 'Nicholas': 456,\n",
       " 'Richard': 457,\n",
       " 'caused': 458,\n",
       " 'slump': 459,\n",
       " 'Chidambaram': 460,\n",
       " 'tearing': 461,\n",
       " 'Syria': 462,\n",
       " 'parked': 463,\n",
       " 'enviable': 464,\n",
       " 'Show': 465,\n",
       " 'Bala': 466,\n",
       " 'Superstar': 467,\n",
       " '19-year-old': 468,\n",
       " 'jeopardy': 469,\n",
       " 'Jaber': 470,\n",
       " 'Angeles-based': 471,\n",
       " 'significance': 472,\n",
       " 'Arero': 473,\n",
       " 'CARE': 474,\n",
       " 'permission': 475,\n",
       " 'Mardan': 476,\n",
       " 'rain': 477,\n",
       " 'legislature': 478,\n",
       " 'Fulani': 479,\n",
       " 'Maghreb': 480,\n",
       " 'some': 481,\n",
       " 'Fatherland': 482,\n",
       " 'Brazilian': 483,\n",
       " 'entitles': 484,\n",
       " 'Visegrad': 485,\n",
       " 'nominee': 486,\n",
       " 'PyeongChang': 487,\n",
       " 'Pulp': 488,\n",
       " 'meanwhile': 489,\n",
       " 'viewing': 490,\n",
       " 'uninhabited': 491,\n",
       " '1,170': 492,\n",
       " 'petition': 493,\n",
       " 'funneled': 494,\n",
       " 'anti-terror': 495,\n",
       " 'guerre': 496,\n",
       " 'treetops': 497,\n",
       " 'chorus': 498,\n",
       " 'fist': 499,\n",
       " 'Federally': 500,\n",
       " 'GlaxoSmithKline': 501,\n",
       " 'Yong-nam': 502,\n",
       " 'Romano': 503,\n",
       " 'shell': 504,\n",
       " 'Aamodt': 505,\n",
       " 'volunteered': 506,\n",
       " '10.2': 507,\n",
       " 'adopts': 508,\n",
       " 'revelry': 509,\n",
       " 'GBAGBO': 510,\n",
       " 'anti-oxidant': 511,\n",
       " 'hangar': 512,\n",
       " 'tanker': 513,\n",
       " 'well-developed': 514,\n",
       " 'Voulgarakis': 515,\n",
       " 'restructuring': 516,\n",
       " 'anti-Semitic': 517,\n",
       " 'assignment': 518,\n",
       " 'scrolls': 519,\n",
       " 'Nursery': 520,\n",
       " 'devolution': 521,\n",
       " 'km-wide': 522,\n",
       " 'empowers': 523,\n",
       " 'rejections': 524,\n",
       " 'specify': 525,\n",
       " 'regards': 526,\n",
       " 'refer': 527,\n",
       " 'frontal': 528,\n",
       " 'raft': 529,\n",
       " 'proof': 530,\n",
       " 'flights': 531,\n",
       " 'POMEGRANATE': 532,\n",
       " 'antigovernment': 533,\n",
       " 'Armin': 534,\n",
       " 'Guild': 535,\n",
       " 'Tax': 536,\n",
       " 'Settlement': 537,\n",
       " 'Fisheries': 538,\n",
       " 'cub': 539,\n",
       " 'baboons': 540,\n",
       " 'gross': 541,\n",
       " 'lifetime': 542,\n",
       " 'lander': 543,\n",
       " 'Moweta': 544,\n",
       " 'life': 545,\n",
       " 'Nawzad': 546,\n",
       " '15': 547,\n",
       " 'impact': 548,\n",
       " 'ANC-led': 549,\n",
       " 'chiefs': 550,\n",
       " 'eastern': 551,\n",
       " '4.5': 552,\n",
       " 'impressive': 553,\n",
       " 'approximately': 554,\n",
       " 'funerals': 555,\n",
       " 'RAVEN': 556,\n",
       " 'patrols': 557,\n",
       " 'al-Bahlul': 558,\n",
       " 'insurer': 559,\n",
       " 'Alkhanov': 560,\n",
       " 'deluxe': 561,\n",
       " \"Ba'ath\": 562,\n",
       " 'al-Dabbagh': 563,\n",
       " 'Timbuktu': 564,\n",
       " 'SUNA': 565,\n",
       " 'Eskom': 566,\n",
       " 'Crewmembers': 567,\n",
       " 'Passy': 568,\n",
       " 'Named': 569,\n",
       " 'Mukasey': 570,\n",
       " 'Punxsutawney': 571,\n",
       " 'Unity': 572,\n",
       " 'Cases': 573,\n",
       " 'defining': 574,\n",
       " 'Tanweer': 575,\n",
       " 'Lapi': 576,\n",
       " 'looser': 577,\n",
       " 'expect': 578,\n",
       " 'Qalat': 579,\n",
       " 'difficult': 580,\n",
       " 'locus': 581,\n",
       " '1929': 582,\n",
       " 'womb': 583,\n",
       " 'ethnocultural': 584,\n",
       " 'insensible': 585,\n",
       " 'left-': 586,\n",
       " '9.68': 587,\n",
       " 'Ovidio': 588,\n",
       " 'affirmation': 589,\n",
       " 'reinstate': 590,\n",
       " 'KITES': 591,\n",
       " 'Rescue': 592,\n",
       " 'Jebii': 593,\n",
       " 'El-Fasher': 594,\n",
       " 'Sonata': 595,\n",
       " 'three-and-a-half': 596,\n",
       " 'aided': 597,\n",
       " 'Nuclear': 598,\n",
       " 'US': 599,\n",
       " 'Fort': 600,\n",
       " 'government-run': 601,\n",
       " 'tales': 602,\n",
       " 'coastal': 603,\n",
       " 'fangs': 604,\n",
       " 'Ashfaq': 605,\n",
       " 'William': 606,\n",
       " 'Kevljani': 607,\n",
       " 'hierarchical': 608,\n",
       " 'Revere': 609,\n",
       " 'supporting-actor': 610,\n",
       " 'pink': 611,\n",
       " 'NFA': 612,\n",
       " 'Russell': 613,\n",
       " 'Azima': 614,\n",
       " 'hyperinflation': 615,\n",
       " 'warehouses': 616,\n",
       " 'rediscovery': 617,\n",
       " 'designated': 618,\n",
       " 'Justine': 619,\n",
       " 'Julio': 620,\n",
       " 'semifinals': 621,\n",
       " 'lied': 622,\n",
       " 'Sloan': 623,\n",
       " 'peatlands': 624,\n",
       " 'disowning': 625,\n",
       " 'Tarique': 626,\n",
       " 'Nabarro': 627,\n",
       " 'exodus': 628,\n",
       " 'exploratory': 629,\n",
       " '350-58': 630,\n",
       " 'Rajah': 631,\n",
       " 'duty': 632,\n",
       " 'registration': 633,\n",
       " 'Nagorno-Karabakh': 634,\n",
       " 'elves': 635,\n",
       " 'garments': 636,\n",
       " 'ISRO': 637,\n",
       " 'luncheon': 638,\n",
       " 'Stade': 639,\n",
       " 'Companies': 640,\n",
       " 'demonstrates': 641,\n",
       " 'motorbike': 642,\n",
       " 'Kind-hearted': 643,\n",
       " '676': 644,\n",
       " '18-day': 645,\n",
       " 'rage': 646,\n",
       " 'MUSEVENI': 647,\n",
       " 'Zacarias': 648,\n",
       " 'Navarro-Valls': 649,\n",
       " 'traditions': 650,\n",
       " 'Almazbek': 651,\n",
       " 'frenzy': 652,\n",
       " 'Lodi': 653,\n",
       " 'holes': 654,\n",
       " 'Philippe': 655,\n",
       " '1776': 656,\n",
       " 'Younous': 657,\n",
       " 'Prime': 658,\n",
       " 'boosts': 659,\n",
       " 'JUPITER': 660,\n",
       " '70-page': 661,\n",
       " 'Yanjin': 662,\n",
       " 'deepwater': 663,\n",
       " 'behaves': 664,\n",
       " 'Then': 665,\n",
       " 'Shieh': 666,\n",
       " 'most-wanted': 667,\n",
       " 'bereavement': 668,\n",
       " 'Nineteen': 669,\n",
       " 'F15': 670,\n",
       " 'hopefuls': 671,\n",
       " 'permit': 672,\n",
       " 'Migratory': 673,\n",
       " 'inauspicious': 674,\n",
       " 'packing': 675,\n",
       " 'two-goal': 676,\n",
       " 'canceling': 677,\n",
       " 'reindeer': 678,\n",
       " 'CRJ-200': 679,\n",
       " 'Anchorage': 680,\n",
       " 'Mir-Kazemi': 681,\n",
       " 'Fatah-allied': 682,\n",
       " 'Petrechemical': 683,\n",
       " 'payday': 684,\n",
       " 'birch-tree': 685,\n",
       " 'Distribution': 686,\n",
       " 'Lagunas': 687,\n",
       " 'prematurely': 688,\n",
       " 'Ginepri': 689,\n",
       " 'preview': 690,\n",
       " 'Kani': 691,\n",
       " 'interim': 692,\n",
       " 'Sarajevo-based': 693,\n",
       " 'nulcear': 694,\n",
       " 'rap': 695,\n",
       " 'mislead': 696,\n",
       " 'exterminated': 697,\n",
       " 'Atalay': 698,\n",
       " 'spammers': 699,\n",
       " 'KTM': 700,\n",
       " 'consider': 701,\n",
       " 'unauthorized': 702,\n",
       " 'Suleimaniya': 703,\n",
       " 'Berrones': 704,\n",
       " 'lookout': 705,\n",
       " '84.9': 706,\n",
       " 'angel': 707,\n",
       " 'firmer': 708,\n",
       " 'Dukeness': 709,\n",
       " 'incomes': 710,\n",
       " 'interested': 711,\n",
       " 'Pham': 712,\n",
       " 'deaths': 713,\n",
       " 'participated': 714,\n",
       " 'destroyer': 715,\n",
       " 'three-person': 716,\n",
       " 'Leeward': 717,\n",
       " 'Integra-A': 718,\n",
       " 'exemption': 719,\n",
       " 'feature-length': 720,\n",
       " 'attack': 721,\n",
       " 'Order': 722,\n",
       " 'Festival': 723,\n",
       " 'Hulk': 724,\n",
       " 'checkup': 725,\n",
       " '9.4': 726,\n",
       " 'Flushing': 727,\n",
       " 'Yvelines': 728,\n",
       " 'flying': 729,\n",
       " 'mementos': 730,\n",
       " 'enterprises': 731,\n",
       " 'exacerbating': 732,\n",
       " 'Bratislava-Trnava': 733,\n",
       " 'torturing': 734,\n",
       " 'disputed': 735,\n",
       " 'VOANews.com': 736,\n",
       " 'Alexeyenko': 737,\n",
       " 'intermediate': 738,\n",
       " 'underlying': 739,\n",
       " 'Live': 740,\n",
       " 'Noormohammadi': 741,\n",
       " 'Hurriyat': 742,\n",
       " 'impulses': 743,\n",
       " 'sun': 744,\n",
       " 'non-emergency': 745,\n",
       " 'visually': 746,\n",
       " 'circular': 747,\n",
       " 'lieutenants': 748,\n",
       " 'confidentiality': 749,\n",
       " 'bonds': 750,\n",
       " 'MPRP': 751,\n",
       " 'Kremlin-backed': 752,\n",
       " 'mudslides': 753,\n",
       " 'hamburgers': 754,\n",
       " '60,000': 755,\n",
       " 'Liempde': 756,\n",
       " 'parade': 757,\n",
       " 'priority': 758,\n",
       " 'fuel': 759,\n",
       " 'Antarctic': 760,\n",
       " 'Shigeru': 761,\n",
       " 'Cotonou': 762,\n",
       " 'Cleland': 763,\n",
       " 'ethic': 764,\n",
       " 'quarterfinal': 765,\n",
       " 'Scot': 766,\n",
       " 'requested': 767,\n",
       " 'Bingol': 768,\n",
       " 'simmers': 769,\n",
       " 'Hokkaido': 770,\n",
       " '18-wheeler': 771,\n",
       " 'chassis': 772,\n",
       " 'always': 773,\n",
       " 'builds': 774,\n",
       " 'Little': 775,\n",
       " 'galaxy': 776,\n",
       " 'extraditing': 777,\n",
       " 'burying': 778,\n",
       " 'equalize': 779,\n",
       " 'instead': 780,\n",
       " 'three': 781,\n",
       " 'qualifications': 782,\n",
       " 'Administrator': 783,\n",
       " 'Durable': 784,\n",
       " 'Gyanendra': 785,\n",
       " 'intoxicating': 786,\n",
       " '377': 787,\n",
       " 'half-hearted': 788,\n",
       " 'zidovudine': 789,\n",
       " 'Hours': 790,\n",
       " 'filberts': 791,\n",
       " 'Mathematically': 792,\n",
       " 'infrared': 793,\n",
       " 'Anderson': 794,\n",
       " 'Youssef': 795,\n",
       " '306': 796,\n",
       " 'religiously': 797,\n",
       " 'ca.': 798,\n",
       " 'Ranch': 799,\n",
       " 'abortion': 800,\n",
       " 'militarism': 801,\n",
       " 'softening': 802,\n",
       " 'cautioning': 803,\n",
       " 'tagging': 804,\n",
       " 'semi-finals': 805,\n",
       " 'requite': 806,\n",
       " \"Shi'ite-dominated\": 807,\n",
       " 'Israeli-Palestinian': 808,\n",
       " 'Brett': 809,\n",
       " 'Mars': 810,\n",
       " 'rebuilt': 811,\n",
       " 'Bonny': 812,\n",
       " 'wanderings': 813,\n",
       " 'Sixty': 814,\n",
       " 'semi-annual': 815,\n",
       " 'fulfills': 816,\n",
       " 'illegals': 817,\n",
       " 'Laszlo': 818,\n",
       " 'depressed': 819,\n",
       " 'moved': 820,\n",
       " 'Kamau': 821,\n",
       " '13th': 822,\n",
       " 'Airport': 823,\n",
       " 'Arsamokov': 824,\n",
       " 'steadily': 825,\n",
       " 'Firebase': 826,\n",
       " 'Bab': 827,\n",
       " 'bloating': 828,\n",
       " 'Progressive': 829,\n",
       " 'RDX': 830,\n",
       " 'miscommunication': 831,\n",
       " '2,633-meter': 832,\n",
       " 'Kurt': 833,\n",
       " 'fiercest': 834,\n",
       " 'welcomes': 835,\n",
       " 'chrome': 836,\n",
       " 'Ishaq': 837,\n",
       " 'al-Khaznawi': 838,\n",
       " 'malicious': 839,\n",
       " 'airs': 840,\n",
       " 'zenith': 841,\n",
       " 'alpine': 842,\n",
       " 'script': 843,\n",
       " 'Haitian': 844,\n",
       " '268': 845,\n",
       " 'sectors': 846,\n",
       " 'By-election': 847,\n",
       " 'animosity': 848,\n",
       " 'assailed': 849,\n",
       " 'serve': 850,\n",
       " 'regional': 851,\n",
       " 'embroiled': 852,\n",
       " 'Nomura': 853,\n",
       " 'pound': 854,\n",
       " 'Andreas': 855,\n",
       " \"Pe'at\": 856,\n",
       " 'ecologic': 857,\n",
       " 'Missouri': 858,\n",
       " 'cancer': 859,\n",
       " 'Myanmar': 860,\n",
       " 'fail': 861,\n",
       " 'redeemed': 862,\n",
       " 'converged': 863,\n",
       " 'emissary': 864,\n",
       " 'cut': 865,\n",
       " 'Resit': 866,\n",
       " 'Ike': 867,\n",
       " 'Serzh': 868,\n",
       " 'damages': 869,\n",
       " 'messes': 870,\n",
       " 'prevented': 871,\n",
       " 'detentions': 872,\n",
       " 'Sachin': 873,\n",
       " 'Ganey': 874,\n",
       " 'concert': 875,\n",
       " 'trigger': 876,\n",
       " '752.2': 877,\n",
       " 'vulnerable': 878,\n",
       " 'Shurja': 879,\n",
       " 'writer': 880,\n",
       " 'Ariel': 881,\n",
       " 'Kenyon': 882,\n",
       " 'Sahafi': 883,\n",
       " 'Pluto': 884,\n",
       " 'appeared': 885,\n",
       " 'blatantly': 886,\n",
       " 'Annunciation': 887,\n",
       " 'pro-Tibet': 888,\n",
       " 'guideline': 889,\n",
       " 'Kappes': 890,\n",
       " 'electrocution': 891,\n",
       " 'inflame': 892,\n",
       " 'Anglo-Irish': 893,\n",
       " 'inter-linked': 894,\n",
       " 'inanimate': 895,\n",
       " 'Hassas': 896,\n",
       " 'Lateef': 897,\n",
       " 'tier': 898,\n",
       " 'Alvaro': 899,\n",
       " 'Kremlin-controlled': 900,\n",
       " 'Minas': 901,\n",
       " 'high-flying': 902,\n",
       " 'faultless': 903,\n",
       " 'broad': 904,\n",
       " 'amass': 905,\n",
       " 'probation': 906,\n",
       " 'Qinghong': 907,\n",
       " 'tamper-proof': 908,\n",
       " '1533': 909,\n",
       " 'Hilla': 910,\n",
       " 'Slough': 911,\n",
       " 'Pondicherry': 912,\n",
       " 'Florent': 913,\n",
       " 'Saleh': 914,\n",
       " 'hillsides': 915,\n",
       " 'Glacieres': 916,\n",
       " 'Conditions': 917,\n",
       " 'combining': 918,\n",
       " '150-year-old': 919,\n",
       " 'Winfrey': 920,\n",
       " 'reminded': 921,\n",
       " 'literally': 922,\n",
       " 'radioactivity': 923,\n",
       " 'pugiliste': 924,\n",
       " 'Sculptor': 925,\n",
       " 'melt': 926,\n",
       " '640': 927,\n",
       " 'repercussions': 928,\n",
       " 'Tri': 929,\n",
       " 'Silva': 930,\n",
       " 'Hanegbi': 931,\n",
       " 'torch': 932,\n",
       " 'Greenpeace': 933,\n",
       " 'Khurasan': 934,\n",
       " 'Peres': 935,\n",
       " 'intensify': 936,\n",
       " 'Advocates': 937,\n",
       " 'Preferences': 938,\n",
       " 'telecommunication': 939,\n",
       " 'helmets': 940,\n",
       " '3.1': 941,\n",
       " 'housekeeping': 942,\n",
       " 'Gras': 943,\n",
       " 'Splendid': 944,\n",
       " '666': 945,\n",
       " 'forsook': 946,\n",
       " 'Muslims': 947,\n",
       " 'Kohl': 948,\n",
       " 'appropriate': 949,\n",
       " 'Mladen': 950,\n",
       " 'Welch': 951,\n",
       " 'Colombian': 952,\n",
       " 'marry': 953,\n",
       " 'lower-house': 954,\n",
       " 'Aqsa': 955,\n",
       " 'Meek': 956,\n",
       " 'L.': 957,\n",
       " 'Tuvalu': 958,\n",
       " 'DiCaprio': 959,\n",
       " 'Karim': 960,\n",
       " 'Two-thirds': 961,\n",
       " 'moans': 962,\n",
       " 'loving': 963,\n",
       " 'greatness': 964,\n",
       " 'founders': 965,\n",
       " 'tolerating': 966,\n",
       " 'ladle': 967,\n",
       " 'expensively': 968,\n",
       " 'bombarded': 969,\n",
       " 'wooden': 970,\n",
       " 'report': 971,\n",
       " 'Mo': 972,\n",
       " 'Samho': 973,\n",
       " 'SAR': 974,\n",
       " 'stay': 975,\n",
       " 'abject': 976,\n",
       " 'Frankenstadion': 977,\n",
       " 'Official': 978,\n",
       " 'Capitol': 979,\n",
       " 'inhale': 980,\n",
       " '&': 981,\n",
       " 'geese': 982,\n",
       " 'Economic': 983,\n",
       " 'well-educated': 984,\n",
       " 'Farabaugh': 985,\n",
       " 'Righteousness': 986,\n",
       " 'nasal': 987,\n",
       " 'over-threw': 988,\n",
       " 'Tshisekedi': 989,\n",
       " 'Bilfinger': 990,\n",
       " 'roofs': 991,\n",
       " 'Jordan-based': 992,\n",
       " 'land-for-peace': 993,\n",
       " 'sites': 994,\n",
       " 'Muslim-majority': 995,\n",
       " 'countrywoman': 996,\n",
       " 'I': 997,\n",
       " 'Bihari': 998,\n",
       " 'approximates': 999,\n",
       " 'pawn': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "vWy7j47QUGR6",
    "outputId": "4d5f2fe1-1c5a-4874-d295-4f07b0ccfc9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art': 10,\n",
       " 'B-eve': 5,\n",
       " 'B-geo': 11,\n",
       " 'B-gpe': 13,\n",
       " 'B-nat': 8,\n",
       " 'B-org': 4,\n",
       " 'B-per': 9,\n",
       " 'B-tim': 14,\n",
       " 'I-art': 7,\n",
       " 'I-eve': 0,\n",
       " 'I-geo': 15,\n",
       " 'I-gpe': 3,\n",
       " 'I-nat': 6,\n",
       " 'I-org': 2,\n",
       " 'I-per': 16,\n",
       " 'I-tim': 12,\n",
       " 'O': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qk4q8kmWU26l",
    "outputId": "00da1f57-bd06-4fc1-e928-7492f74d705b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biggest sentence has 104 words\n"
     ]
    }
   ],
   "source": [
    "largest_sen = max(len(sen) for sen in sent)\n",
    "print('biggest sentence has {} words'.format(largest_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "fpR60ANfVEix",
    "outputId": "a84e7a45-0ef5-4973-e87c-68b6e9891e0d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXgElEQVR4nO3df0zV1/3H8ecF1BauAvdeqQE1E3/8USrDeIlopjC925LafeNXjUk7l9g036Vlg6DZMmyTuWSrI20pRMTQVKNL26RZjJJ232VLbhiYjZhc5EdXuom2btGgIvdzZVzAivD5/mF2v9qKcBUucM/r8Vfv534+9573Pfjqueeee67Dtm0bERExQsJ0N0BERGJHoS8iYhCFvoiIQRT6IiIGUeiLiBhEoS8iYpCkiZz04x//mCeeeIKEhAQSExOpqKggHA5TVVXFjRs3WLhwIXv37sXpdGLbNsePH6etrY158+ZRXFxMdnY2AI2NjZw6dQqA7du3U1RUNO5zd3d3R1WQx+Oht7c3qmtmK9Uan1RrfIplrZmZmWPeN6HQBzhw4AALFiyI3K6vr2f16tVs27aN+vp66uvr2b17N21tbVy7do1Dhw5x4cIFjh49ysGDBwmHw5w8eZKKigoAysvL8Xq9OJ3OxyhNRESi8cjTO4FAgMLCQgAKCwsJBAIAtLS0sGnTJhwOB6tWrWJgYIBQKER7ezu5ubk4nU6cTie5ubm0t7dPThUiIjIhEx7pv/766wB85zvfwefz0dfXR3p6OgBpaWn09fUBYFkWHo8ncp3b7cayLCzLwu12R467XC4sy/ra8/j9fvx+PwAVFRX3PdaECkpKivqa2Uq1xifVGp9mSq0TCv1f/epXuFwu+vr6+PWvf/21+SKHw4HD4ZiUBvl8Pnw+X+R2tHNgmiOMT6o1PqnWqfGwOf0JTe+4XC4AUlNTyc/P5+LFi6SmphIKhQAIhUKR+X6Xy3VfYcFgEJfLhcvlIhgMRo5blhV5XBERiY1xQ//WrVsMDQ1F/vuTTz5h6dKleL1empqaAGhqaiI/Px8Ar9fLmTNnsG2brq4ukpOTSU9PJy8vj46ODsLhMOFwmI6ODvLy8qawNBER+apxp3f6+vp46623ABgZGeFb3/oWeXl5LF++nKqqKhoaGiJLNgHWrFlDa2srpaWlzJ07l+LiYgCcTic7duxg//79AOzcuVMrd0REYswx07dW1jr9sanW+KRa49OsmtMXEZH4MOElmzJzjPzPfwFw/SvHE9/9KPaNEZFZRSN9ERGDKPRFRAyi0BcRMYhCX0TEIAp9ERGDaPVOHPnPqp4H0coeEQGN9EVEjKLQFxExiEJfRMQgCn0REYMo9EVEDKLVOzPYw1bjiIg8Co30RUQMotAXETGIQl9ExCAKfRERg+iDXEOM9aGwtmcQMYtG+iIiBlHoi4gYRKEvImIQhb6IiEEU+iIiBlHoi4gYRKEvImIQhb6IiEEU+iIiBlHoi4gYRKEvImIQhb6IiEEU+iIiBlHoi4gYRKEvImKQCe+nPzo6Snl5OS6Xi/Lycnp6eqiurqa/v5/s7GxKSkpISkpieHiYw4cP88UXXzB//nzKysrIyMgA4PTp0zQ0NJCQkMCLL75IXl7elBUmIiJfN+GR/h/+8AeysrIit99//322bt1KTU0NKSkpNDQ0ANDQ0EBKSgo1NTVs3bqVDz74AIArV67Q3NzM22+/zWuvvcaxY8cYHR2d5HJERORhJhT6wWCQ1tZWtmzZAoBt23R2dlJQUABAUVERgUAAgJaWFoqKigAoKCjg008/xbZtAoEAGzZsYM6cOWRkZLBo0SIuXrw4BSWJiMhYJjS9c+LECXbv3s3Q0BAA/f39JCcnk5iYCIDL5cKyLAAsy8LtdgOQmJhIcnIy/f39WJbFypUrI4957zX38vv9+P1+ACoqKvB4PNEVlJQU9TUz1fUYPMdsea3iqV/Ho1rj00ypddzQP3fuHKmpqWRnZ9PZ2TnlDfL5fPh8vsjt3t7eqK73eDxRXzPdxvr92liYLa/VbOzXR6Va41Msa83MzBzzvnFD//z587S0tNDW1sbt27cZGhrixIkTDA4OMjIyQmJiIpZl4XK5gLsj+GAwiNvtZmRkhMHBQebPnx85/h/3XiMiIrEx7pz+Cy+8QF1dHbW1tZSVlfHMM89QWlpKTk4OZ8+eBaCxsRGv1wvA2rVraWxsBODs2bPk5OTgcDjwer00NzczPDxMT08PV69eZcWKFVNXmYiIfM2El2x+1Q9+8AOqq6v58MMPWbZsGZs3bwZg8+bNHD58mJKSEpxOJ2VlZQAsWbKE9evXs2/fPhISEnjppZdISNDXBEREYslh27Y93Y14mO7u7qjOn41zhNM5p5/47kfT9tzRmI39+qhUa3yaKXP6GmqLiBhEoS8iYpBHntOX+DDW1NJsmfYRkehopC8iYhCFvoiIQRT6IiIGUeiLiBhEoS8iYhCFvoiIQRT6IiIGUeiLiBhEoS8iYhCFvoiIQRT6IiIGUeiLiBhEG67F0HTumy8iAhrpi4gYRaEvImIQhb6IiEEU+iIiBlHoi4gYRKEvImIQhb6IiEEU+iIiBlHoi4gYRKEvImIQhb6IiEEU+iIiBlHoi4gYRKEvImIQhb6IiEEU+iIiBtGPqMgDjfWDL4nvfhTjlojIZNJIX0TEIOOO9G/fvs2BAwe4c+cOIyMjFBQUsGvXLnp6eqiurqa/v5/s7GxKSkpISkpieHiYw4cP88UXXzB//nzKysrIyMgA4PTp0zQ0NJCQkMCLL75IXl7elBcoIiL/b9yR/pw5czhw4ABvvvkmb7zxBu3t7XR1dfH++++zdetWampqSElJoaGhAYCGhgZSUlKoqalh69atfPDBBwBcuXKF5uZm3n77bV577TWOHTvG6Ojo1FYnIiL3GTf0HQ4HTzzxBAAjIyOMjIzgcDjo7OykoKAAgKKiIgKBAAAtLS0UFRUBUFBQwKeffopt2wQCATZs2MCcOXPIyMhg0aJFXLx4cYrKEhGRB5nQB7mjo6P8/Oc/59q1a3zve9/jqaeeIjk5mcTERABcLheWZQFgWRZutxuAxMREkpOT6e/vx7IsVq5cGXnMe6+5l9/vx+/3A1BRUYHH44muoKSkqK+JlevT3YBJMF2v7Uzu18mmWuPTTKl1QqGfkJDAm2++ycDAAG+99Rbd3d1T1iCfz4fP54vc7u3tjep6j8cT9TUycdP12prUr6o1PsWy1szMzDHvi2r1TkpKCjk5OXR1dTE4OMjIyAhwd3TvcrmAuyP4YDAI3J0OGhwcZP78+fcd/+o1IiISG+OG/r///W8GBgaAuyt5PvnkE7KyssjJyeHs2bMANDY24vV6AVi7di2NjY0AnD17lpycHBwOB16vl+bmZoaHh+np6eHq1ausWLFiisoSEZEHGXd6JxQKUVtby+joKLZts379etauXcvixYuprq7mww8/ZNmyZWzevBmAzZs3c/jwYUpKSnA6nZSVlQGwZMkS1q9fz759+0hISOCll14iIUFfExARiSWHbdv2dDfiYaL9/GAmzxGO9S3X2WS6vpE7k/t1sqnW+DQr5/RFRGR2U+iLiBhEG65NgXiYxhGR+KSRvoiIQRT6IiIGUeiLiBhEoS8iYhCFvoiIQRT6IiIGUeiLiBhEoS8iYhCFvoiIQRT6IiIGUeiLiBhEoS8iYhCFvoiIQRT6IiIGUeiLiBhE++lLVMb6rYDp+hlFEYmORvoiIgZR6IuIGEShLyJiEIW+iIhBFPoiIgZR6IuIGEShLyJiEIW+iIhBFPoiIgZR6IuIGEShLyJiEO298xjG2odGRGSm0khfRMQgCn0REYOMO73T29tLbW0tN2/exOFw4PP5ePbZZwmHw1RVVXHjxg0WLlzI3r17cTqd2LbN8ePHaWtrY968eRQXF5OdnQ1AY2Mjp06dAmD79u0UFRVNaXEiInK/cUM/MTGRH/7wh2RnZzM0NER5eTm5ubk0NjayevVqtm3bRn19PfX19ezevZu2tjauXbvGoUOHuHDhAkePHuXgwYOEw2FOnjxJRUUFAOXl5Xi9XpxO55QXKSIid407vZOenh4ZqT/55JNkZWVhWRaBQIDCwkIACgsLCQQCALS0tLBp0yYcDgerVq1iYGCAUChEe3s7ubm5OJ1OnE4nubm5tLe3T2FpIiLyVVGt3unp6eHSpUusWLGCvr4+0tPTAUhLS6Ovrw8Ay7LweDyRa9xuN5ZlYVkWbrc7ctzlcmFZ1teew+/34/f7AaioqLjvsSZUUFJS1Nc8qusxeZbZYapf81j263RTrfFpptQ64dC/desWlZWV7Nmzh+Tk5PvuczgcOByOSWmQz+fD5/NFbvf29kZ1vcfjifoaeXxT/Zqb1K+qNT7FstbMzMwx75vQ6p07d+5QWVnJxo0bWbduHQCpqamEQiEAQqEQCxYsAO6O4O8tLBgM4nK5cLlcBIPByHHLsnC5XNFXIyIij2zc0Ldtm7q6OrKysnjuuecix71eL01NTQA0NTWRn58fOX7mzBls26arq4vk5GTS09PJy8ujo6ODcDhMOBymo6ODvLy8KSpLREQeZNzpnfPnz3PmzBmWLl3Kz372MwCef/55tm3bRlVVFQ0NDZElmwBr1qyhtbWV0tJS5s6dS3FxMQBOp5MdO3awf/9+AHbu3KmVOyIiMeawbdue7kY8THd3d1Tnx3LeTNsw/L/Edz+a0sfX3G98Uq1T47Hn9EVEJD4o9EVEDKLQFxExiEJfRMQg2k9fptRYH3ZP9Qe/IvJgGumLiBhEoS8iYhBN78ik0HcWRGYHjfRFRAyi0BcRMYhCX0TEIAp9ERGDKPRFRAyi0BcRMYhCX0TEIAp9ERGDKPRFRAyi0BcRMYhCX0TEIAp9ERGDKPRFRAyi0BcRMYi2Vp4AbRssIvFCI30REYMo9EVEDKLQFxExiEJfRMQgCn0REYMo9EVEDKLQFxExiEJfRMQgCn0REYMo9EVEDKLQFxExyLh77xw5coTW1lZSU1OprKwEIBwOU1VVxY0bN1i4cCF79+7F6XRi2zbHjx+nra2NefPmUVxcTHZ2NgCNjY2cOnUKgO3bt1NUVDR1VYmIyAONO9IvKiri1Vdfve9YfX09q1ev5tChQ6xevZr6+noA2trauHbtGocOHeJHP/oRR48eBe7+T+LkyZMcPHiQgwcPcvLkScLh8BSUIyIiDzNu6D/99NM4nc77jgUCAQoLCwEoLCwkEAgA0NLSwqZNm3A4HKxatYqBgQFCoRDt7e3k5ubidDpxOp3k5ubS3t4+BeWIiMjDPNLWyn19faSnpwOQlpZGX18fAJZl4fF4Iue53W4sy8KyLNxud+S4y+XCsqwHPrbf78fv9wNQUVFx3+NNRFJSUtTXjOf6pD6aADOiX2cq1RqfZkqtj72fvsPhwOFwTEZbAPD5fPh8vsjt3t7eqK73eDxRXyOxp34dm2qNT7GsNTMzc8z7Hmn1TmpqKqFQCIBQKMSCBQuAuyP4e4sKBoO4XC5cLhfBYDBy3LIsXC7Xozy1iIg8hkcKfa/XS1NTEwBNTU3k5+dHjp85cwbbtunq6iI5OZn09HTy8vLo6OggHA4TDofp6OggLy9v8qoQEZEJGXd6p7q6ms8++4z+/n5efvlldu3axbZt26iqqqKhoSGyZBNgzZo1tLa2Ulpayty5cykuLgbA6XSyY8cO9u/fD8DOnTu/9uGwiIhMPYdt2/Z0N+Jhuru7ozp/KubN9Bu5ky/x3Y+iOl9zv/FJtU6NSZ/TFxGR2UmhLyJiEIW+iIhBFPoiIgZR6IuIGEShLyJiEIW+iIhBHnvvnXii9fgiEu800hcRMYhG+jItxnpXFe03dUUkOhrpi4gYRKEvImIQhb6IiEEU+iIiBlHoi4gYRKEvImIQhb6IiEG0Tl9mlDG/FX26ObYNEYlTGumLiBhEoS8iYhCFvoiIQRT6IiIGUeiLiBhEoS8iYhCFvoiIQbROX2aF6/+94YHHtf++SHQ00hcRMYhCX0TEIAp9ERGDGDmnP+b+LjLr6Ld2RaKjkb6IiEEU+iIiBjFyekfin6Z9RB5MI30REYPEfKTf3t7O8ePHGR0dZcuWLWzbti3WTRCDPcqH+Hp3IPEkpiP90dFRjh07xquvvkpVVRV//etfuXLlSiybICJitJiO9C9evMiiRYt46qmnANiwYQOBQIDFixdPyfNpaaZMhsn6OxrrHcNXH//6OOeLPI6Yhr5lWbjd7shtt9vNhQsX7jvH7/fj9/sBqKioIDMzM+rniVzzvy2P3liRWDH87/RR/o3PVjOh1hn3Qa7P56OiooKKiopHur68vHySWzRzqdb4pFrj00ypNaah73K5CAaDkdvBYBCXyxXLJoiIGC2mob98+XKuXr1KT08Pd+7cobm5Ga/XG8smiIgYLfGXv/zlL2P1ZAkJCSxatIiamhr++Mc/snHjRgoKCib9ebKzsyf9MWcq1RqfVGt8mgm1Omzbtqe7ESIiEhsz7oNcERGZOgp9ERGDxM2Ga/G8vUNvby+1tbXcvHkTh8OBz+fj2WefJRwOU1VVxY0bN1i4cCF79+7F6XROd3MnxejoKOXl5bhcLsrLy+np6aG6upr+/n6ys7MpKSkhKWn2//kODAxQV1fH5cuXcTgcvPLKK2RmZsZlv/7+97+noaEBh8PBkiVLKC4u5ubNm3HTr0eOHKG1tZXU1FQqKysBxvw3ats2x48fp62tjXnz5lFcXBy7+X47DoyMjNg/+clP7GvXrtnDw8P2T3/6U/vy5cvT3axJY1mW/fnnn9u2bduDg4N2aWmpffnyZfu9996zT58+bdu2bZ8+fdp+7733prOZk+rjjz+2q6ur7d/85je2bdt2ZWWl/Ze//MW2bdt+55137D/96U/T2bxJU1NTY/v9ftu2bXt4eNgOh8Nx2a/BYNAuLi62v/zyS9u27/bnn//857jq187OTvvzzz+39+3bFzk2Vl+eO3fOfv311+3R0VH7/Pnz9v79+2PWzriY3rl3e4ekpKTI9g7xIj09PTIKePLJJ8nKysKyLAKBAIWFhQAUFhbGTc3BYJDW1la2bNkCgG3bdHZ2RlZ6FRUVxUWtg4OD/P3vf2fz5s0AJCUlkZKSErf9Ojo6yu3btxkZGeH27dukpaXFVb8+/fTTX3tHNlZftrS0sGnTJhwOB6tWrWJgYIBQKBSTds7O91FfMZHtHeJFT08Ply5dYsWKFfT19ZGeng5AWloafX1909y6yXHixAl2797N0NAQAP39/SQnJ5OYmAjc/ZKfZVnT2cRJ0dPTw4IFCzhy5Aj/+te/yM7OZs+ePXHZry6Xi+9///u88sorzJ07l29+85tkZ2fHZb/ea6y+tCwLj8cTOc/tdmNZVuTcqRQXI31T3Lp1i8rKSvbs2UNycvJ99zkcDhwOxzS1bPKcO3eO1NTUGbGeeaqNjIxw6dIlvvvd7/LGG28wb9486uvr7zsnXvo1HA4TCASora3lnXfe4datW7S3t093s2JqpvRlXIz0Tdje4c6dO1RWVrJx40bWrVsHQGpqKqFQiPT0dEKhEAsWLJjmVj6+8+fP09LSQltbG7dv32ZoaIgTJ04wODjIyMgIiYmJWJYVF/3rdrtxu92sXLkSgIKCAurr6+OyX//2t7+RkZERqWXdunWcP38+Lvv1XmP1pcvlore3N3JeLDMrLkb68b69g23b1NXVkZWVxXPPPRc57vV6aWpqAqCpqYn8/PzpauKkeeGFF6irq6O2tpaysjKeeeYZSktLycnJ4ezZswA0NjbGRf+mpaXhdrvp7u4G7gbj4sWL47JfPR4PFy5c4Msvv8S27Uit8div9xqrL71eL2fOnMG2bbq6ukhOTo7J1A7E0TdyW1tb+e1vf8vo6Cjf/va32b59+3Q3adL84x//4Be/+AVLly6NvD18/vnnWblyJVVVVfT29sbV0r7/6Ozs5OOPP6a8vJzr169TXV1NOBxm2bJllJSUMGfOnOlu4mP75z//SV1dHXfu3CEjI4Pi4mJs247Lfv3d735Hc3MziYmJfOMb3+Dll1/Gsqy46dfq6mo+++wz+vv7SU1NZdeuXeTn5z+wL23b5tixY3R0dDB37lyKi4tZvnx5TNoZN6EvIiLji4vpHRERmRiFvoiIQRT6IiIGUeiLiBhEoS8iYhCFvoiIQRT6IiIG+T98/oDqOK9iUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the distribution of length of sentences\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXrlEkoMV6a_"
   },
   "outputs": [],
   "source": [
    "# In order to feed our sentences into a LSTM network, they all need to be the same size. looking at the distribution graph, we can set the \n",
    "# length of all sentences to 50 and add a generic word for the empty spaces; this process is called padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdQlkFg3V_Qr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XNBrqbJZnz0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RlVdVHia_kp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "NF2jz4tK74vr",
    "outputId": "ec29dff9-9acc-4ace-ea98-994142b98186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 50)            1758950   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 17)            3417      \n",
      "=================================================================\n",
      "Total params: 1,883,167\n",
      "Trainable params: 1,883,167\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_word = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=num_words, output_dim=50, input_length=max_len)(input_word)\n",
    "model = SpatialDropout1D(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(num_tags, activation=\"softmax\"))(model)\n",
    "model = Model(input_word, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNWwZ7aKGFwc"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5y3GS6DGq4a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#from livelossplot.tf_keras import PlotLossesCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "XHGYAL5zHnLq",
    "outputId": "7bd80602-685b-4dbe-8af0-46cbb121602c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9593\n",
      "Epoch 00001: val_loss improved from inf to 0.06729, saving model to model_weights.h5\n",
      "1199/1199 [==============================] - 580s 483ms/step - loss: 0.1784 - accuracy: 0.9593 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "Epoch 2/3\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9850\n",
      "Epoch 00002: val_loss improved from 0.06729 to 0.05214, saving model to model_weights.h5\n",
      "1199/1199 [==============================] - 572s 477ms/step - loss: 0.0505 - accuracy: 0.9850 - val_loss: 0.0521 - val_accuracy: 0.9844\n",
      "Epoch 3/3\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9886\n",
      "Epoch 00003: val_loss improved from 0.05214 to 0.04771, saving model to model_weights.h5\n",
      "1199/1199 [==============================] - 574s 478ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.0477 - val_accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
    "\n",
    "callbacks = [chkpt, early_stopping]\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test,y_test),\n",
    "    batch_size=32, \n",
    "    epochs=3,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "XkkbhZwvWK7J",
    "outputId": "372f377d-9034-43aa-ac3e-44befc4d8a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 11s 37ms/step - loss: 0.0477 - accuracy: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04770501330494881, 0.9857693910598755]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "colab_type": "code",
    "id": "DBwmvb6aWUDp",
    "outputId": "9a75d878-df8b-4a82-a08a-1939616bd7c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           True \t Pred\n",
      "\n",
      "------------------------------\n",
      "At             O\tO\n",
      "least          O\tO\n",
      "eight          O\tO\n",
      "people         O\tO\n",
      "have           O\tO\n",
      "been           O\tO\n",
      "killed         O\tO\n",
      "in             O\tO\n",
      "the            O\tO\n",
      "fighting       O\tO\n",
      ".              O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n",
      "coast          O\tO\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, x_test.shape[0]) #659\n",
    "p = model.predict(np.array([x_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "y_true = y_test[i]\n",
    "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(\"-\" *30)\n",
    "for w, true, pred in zip(x_test[i], y_true, p[0]):\n",
    "    print(\"{:15}{}\\t{}\".format(words[w-1], tags[true], tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1KvPqj92X2kW",
    "outputId": "3c1f5c88-71a2-4459-c3cc-0369f737fbce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Charls', 'lives', 'in', 'London.', 'He', 'can', 'speak', 'fluent', 'English']"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sentence='Charls lives in London. He can speak fluent English'\n",
    "word=my_sentence.split(' ')\n",
    "word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "P7DQka01ZYoh",
    "outputId": "bb3a5ce9-1dc2-42f4-af52-39ae5573fc73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Charls': 1,\n",
       " 'English': 9,\n",
       " 'He': 5,\n",
       " 'London.': 4,\n",
       " 'can': 6,\n",
       " 'fluent': 8,\n",
       " 'in': 3,\n",
       " 'lives': 2,\n",
       " 'speak': 7}"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {w: i + 1 for i, w in enumerate(word)}\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "A4rN-CkRbz34",
    "outputId": "33862f33-73cf-467a-acac-1e5ab98c76e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178])"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list=[]\n",
    "for key,value in word2idx.items():\n",
    "  x_list.append(value)\n",
    "\n",
    "while len(x_list)<50:\n",
    "  x_list.append(num_words-1)\n",
    "\n",
    "x_list=np.array(x_list)\n",
    "\n",
    "x_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "p-fV24zSZseC",
    "outputId": "4e47ab5e-cde1-421b-91be-12a69b86a205"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(np.array([x_list]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "p\n",
    "\n",
    "# 'Charls lives in London. He can speak fluent English'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "RtKH6pB7e_dN",
    "outputId": "e2688960-4a13-4f0f-ea37-659b96096324"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art': 10,\n",
       " 'B-eve': 5,\n",
       " 'B-geo': 11,\n",
       " 'B-gpe': 13,\n",
       " 'B-nat': 8,\n",
       " 'B-org': 4,\n",
       " 'B-per': 9,\n",
       " 'B-tim': 14,\n",
       " 'I-art': 7,\n",
       " 'I-eve': 0,\n",
       " 'I-geo': 15,\n",
       " 'I-gpe': 3,\n",
       " 'I-nat': 6,\n",
       " 'I-org': 2,\n",
       " 'I-per': 16,\n",
       " 'I-tim': 12,\n",
       " 'O': 1}"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "id": "AcbqauhvgEfV",
    "outputId": "3f0c11eb-ea92-4179-923a-2af0d3f935fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-per',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict={}\n",
    "\n",
    "for key,value in tag2idx.items():\n",
    "  entity_dict[value]=key\n",
    "\n",
    "entities=[]\n",
    "\n",
    "for i in p[0]:\n",
    "  entities.append(entity_dict[i])\n",
    "\n",
    "entities\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Named Entity Recognition(run with GPU).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
